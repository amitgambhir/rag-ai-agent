import os
import sys
import streamlit as st
from dotenv import load_dotenv

# â”€â”€â”€ Load environment â”€â”€â”€
ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
if ROOT not in sys.path:
    sys.path.insert(0, ROOT)
load_dotenv(os.path.join(ROOT, ".env"))

# â”€â”€â”€ App Modules â”€â”€â”€
from modules.rag_qa import RAGQA
from modules.summarizer import Summarizer
from modules.memory import ChatMemory
from modules.planner import Planner
from modules.fallback import fallback_answer
from modules.rag_ingest import ingest_documents

# â”€â”€â”€ Auth Setup â”€â”€â”€
USERNAME = os.getenv("APP_USERNAME")
PASSWORD = os.getenv("APP_PASSWORD")
if not USERNAME or not PASSWORD:
    st.error("âš ï¸ Missing APP_USERNAME or APP_PASSWORD in .env")
    st.stop()

# â”€â”€â”€ Streamlit Page Config â”€â”€â”€
st.set_page_config(page_title="AI Agent MCP", layout="wide")
st.title("ğŸ¤– AI Agent MCP")

# â”€â”€â”€ Session State Init â”€â”€â”€
if "auth" not in st.session_state:
    st.session_state.auth = False
if "rag" not in st.session_state:
    st.session_state.rag = RAGQA()
if "summ" not in st.session_state:
    st.session_state.summ = Summarizer()
if "plan" not in st.session_state:
    st.session_state.plan = Planner()
if "mem" not in st.session_state:
    st.session_state.mem = ChatMemory()
if "hist" not in st.session_state:
    st.session_state.hist = []
if "use_gpt_fallback" not in st.session_state:
    st.session_state.use_gpt_fallback = False

# â”€â”€â”€ Login Form â”€â”€â”€
if not st.session_state.auth:
    st.subheader("ğŸ” Login")
    user = st.text_input("Username")
    pwd = st.text_input("Password", type="password")
    if st.button("Login"):
        if user == USERNAME and pwd == PASSWORD:
            st.session_state.auth = True
            st.rerun()
        else:
            st.error("âŒ Invalid credentials")
    st.stop()

# â”€â”€â”€ Sidebar Tools â”€â”€â”€
st.sidebar.header("Settings & Tools")

if st.sidebar.button("ğŸ” Refresh Vector Store"):
    try:
        # Step 1: Manually remove RAG instance (free up Chroma lock)
        st.session_state.rag = None  

        # Step 2: Delete old vectorstore dir
        import shutil
        from modules.config import PERSIST_DIR
        if os.path.exists(PERSIST_DIR):
            shutil.rmtree(PERSIST_DIR)

        # Step 3: Run ingestion pipeline (rebuild vectorstore)
        with st.spinner("â™»ï¸ Rebuilding vector storeâ€¦"):
            rag_ingest.ingest_documents()

        # Step 4: Reinitialize RAG module
        st.session_state.rag = RAGQA(force_reload=True)
        st.sidebar.success("âœ… Vector store refreshed successfully")

    except Exception as e:
        st.sidebar.error(f"âŒ Ingestion error: {e}")

if st.sidebar.button("ğŸ”„ Reset Conversation"):
    st.session_state.mem.clear()
    st.session_state.hist = []
    st.session_state.auth = True
    st.experimental_rerun()

st.session_state.use_gpt_fallback = st.sidebar.checkbox(
    "Enable GPT fallback", value=st.session_state.use_gpt_fallback
)

# â”€â”€â”€ Main Interaction â”€â”€â”€
query = st.text_input("Ask a question:")
length = st.slider("Summary Length (max tokens)", min_value=50, max_value=1000, value=300, step=50)

if query:
    try:
        # 1ï¸âƒ£ Plan
        steps = st.session_state.plan.plan(query)
        st.markdown("### ğŸ” Plan")
        st.write(steps)

        # 2ï¸âƒ£ Add user message
        st.session_state.mem.add_user_message(query)
        st.session_state.hist.append({"role": "user", "content": query})

        # 3ï¸âƒ£ RAG query
        answer, sources = st.session_state.rag.query(query)

        # 4ï¸âƒ£ Fallback if no RAG result
        if (not isinstance(answer, str) or not answer.strip()) and st.session_state.use_gpt_fallback:
            with st.spinner("ğŸ’¬ No RAG hit â€” asking ChatGPTâ€¦"):
                fallback_response = fallback_answer(query)
                if callable(fallback_response):
                    answer = "[Invalid fallback result: function instead of string]"
                else:
                    answer = str(fallback_response)
                sources = [{"metadata": {"source": "ğŸ’¬ ChatGPT (fallback)"}}]

        # 5ï¸âƒ£ Summarize
        summary = st.session_state.summ.summarize(answer, max_tokens=length)

        # 6ï¸âƒ£ Add AI message
        st.session_state.mem.add_ai_message(summary)
        st.session_state.hist.append({"role": "assistant", "content": summary})

        # 7ï¸âƒ£ Display
        st.markdown("### ğŸ’¬ Answer")
        st.write(summary)

        if sources:
            st.markdown("### ğŸ“š Sources")
            for doc in sources:
                src = doc.metadata.get("source", "unknown")
                st.write(f"- {os.path.basename(src)}")

    except Exception as e:
        st.error(f"ğŸš¨ {e}")

# â”€â”€â”€ Chat History â”€â”€â”€
if st.checkbox("Show Chat History"):
    st.markdown("### ğŸ“ History")
    for msg in st.session_state.hist:
        who = "You" if msg["role"] == "user" else "AI"
        st.write(f"**{who}:** {msg['content']}")

st.caption("Â© AI RAG Agent - powered with Streamlit, Chroma, OpenAI, and LangChain")
